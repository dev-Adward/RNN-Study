{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83dbc17b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Flatten, Dense, Dropout\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0e9fc5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_data = pd.read_csv('D:/AI/bitcoin/bitcoin_2017_to_2023.csv')\n",
    "\n",
    "# print(csv_data)\n",
    "data = csv_data.drop(columns=[\"quote_asset_volume\",\"number_of_trades\"])\n",
    "print(data)\n",
    "\n",
    "# train_input, val_input, train_target, val_target = train_test_split(train_input, train_target, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9deeb00",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data[['open', 'high', 'low', 'close', 'volume']]\n",
    "\n",
    "# Normalize the data using Min-Max scaling\n",
    "scaler = MinMaxScaler()\n",
    "data_normalized = scaler.fit_transform(data)\n",
    "\n",
    "# Prepare the input and target data for the RNN\n",
    "sequence_length = 10  # Length of sequences for input data\n",
    "\n",
    "# Generate sequences for RNN\n",
    "sequences = []\n",
    "targets = []\n",
    "for i in range(len(data_normalized) - sequence_length):\n",
    "    sequences.append(data_normalized[i:i+sequence_length])\n",
    "    targets.append(data_normalized[i+sequence_length, 3])  # Predicting 'close' price\n",
    "\n",
    "# Convert to numpy arrays\n",
    "sequences = np.array(sequences)\n",
    "targets = np.array(targets)\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(sequences, targets, test_size=0.2, random_state=42)\n",
    "\n",
    "# Build the RNN model\n",
    "model = Sequential()\n",
    "model.add(SimpleRNN(64, input_shape=(sequence_length, 5), activation='relu'))\n",
    "model.add(Dense(1))  # Output layer with one neuron for regression\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train, epochs=10, batch_size=32, validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbd13897",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
